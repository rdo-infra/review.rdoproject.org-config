- builder:
    name: 'oooq_dlrn_build_packages'
    defaults: global
    builders:
      - shell: |
          # This builder should build DLRN packages and install the repo
          # on this and all sub_nodes
          # tripleo-gate needs to cloned into a roles/ directory

          # Install some requirements for DLRN
          sudo yum install -y python-virtualenv gcc
          virtualenv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install ansible

          mkdir roles
          git clone https://github.com/redhat-openstack/ansible-role-tripleo-gate roles/tripleo-gate

          # Create config files for ansible
          cat << EOF > hosts
            localhost ansible_connection=local
          EOF

          cat << EOF > build-packages.yaml
          ---
          - name: Build custom RPMs
            hosts: localhost
            roles:
              - { role: tripleo-gate, artg_compressed_gating_repo: '${WORKSPACE}/repo.tar.gz' }
          EOF

          # For now we need some test change of an upstream project to make
          # this playbook work correctly.
          # TODO: Delete these, replace with actual changes.
          export GERRIT_PATCHSET_REVISION=404803ebe0770b31d0e78665ff5b5c64daf9346e
          export GERRIT_HOST=review.openstack.org
          export GERRIT_BRANCH=master
          export GERRIT_CHANGE_ID=369668

          # Finally tell ansible to run the playbook to create scripts
          ansible-playbook -i hosts -vvvv build-packages.yaml

          # Untar and create the repo on localhost
          tar zxvf repo.tar.gz
          cat << EOF | sudo tee /etc/yum.repos.d/testing.repo
          [testing]
          name=Repo for testing change
          baseurl=file://${WORKSPACE}/gating_repo
          priority=15
          gpgcheck=0
          EOF

          # Copy the repo to each sub_node
          SSH_ARGS="-o IdentityFile=/etc/nodepool/id_rsa -o User=jenkins -o StrictHostKeyChecking=no"

          while read sub; do
            ssh ${SSH_ARGS} ${sub} mkdir -p ${WORKSPACE}
            scp -r ${SSH_ARGS} ${WORKSPACE}/gating_repo ${sub}:${WORKSPACE}/
            scp ${SSH_ARGS} /etc/yum.repos.d/testing.repo ${sub}:testing.repo
            ssh ${SSH_ARGS} ${sub} "sudo chown root:root testing.repo; sudo mv testing.repo /etc/yum.repos.d/"
          done < /etc/nodepool/sub_nodes_private

- builder:
    name: 'setup_multinode'
    defaults: global
    builders:
      - shell: |
          # First we need to install tripleo-ci on each subnode
          SSH_ARGS="-o IdentityFile=/etc/nodepool/id_rsa -o User=jenkins -o StrictHostKeyChecking=no"

          while read sub; do
            ssh ${SSH_ARGS} ${sub} mkdir -p ${WORKSPACE}/tripleo
            ssh ${SSH_ARGS} ${sub} git clone https://git.openstack.org/openstack-infra/tripleo-ci ${WORKSPACE}/tripleo/tripleo-ci
          done < /etc/nodepool/sub_nodes_private

          # Create tripleo root directory that tripleo.sh expects
          mkdir ${WORKSPACE}/tripleo
          export TRIPLEO_ROOT=${WORKSPACE}/tripleo

          # Create a 'new' symlink for devstack to use
          export BASE=${WORKSPACE}/tripleo
          ln -sf ${WORKSPACE}/tripleo ${WORKSPACE}/tripleo/new

          git clone https://git.openstack.org/openstack-infra/tripleo-ci
          cd tripleo-ci
          ./scripts/tripleo.sh --repo-setup
          ./scripts/tripleo.sh --multinode-setup

- builder:
    name: create_multinode_inventory
    builders:
      - shell: |
          mkdir -p ${WORKSPACE}/workdir
          INVENTORY_FILE=${INVENTORY_FILE:-$WORKSPACE/workdir/hosts}
          echo << EOF > ${INVENTORY_FILE}
          127.0.0.2 ansible_ssh_user=jenkins

          [virthost]
          127.0.0.2 ansible_ssh_user=jenkins

          [undercloud]
          127.0.0.2 ansible_ssh_user=jenkins

          [overcloud]
          EOF

          # TODO: replace sub_nodes with their vxlan addresses
          # The /etc/nodepool/sub_nodes_private file contains a list of IPs that
          # have been allocated as additional nodes by nodepool for this job
          # run. These nodes have been set up according to the ready-script
          # listed in the node definition used for the job.
          while read sub; do
            echo ${sub} >> ${INVENTORY_FILE}
          done < /etc/nodepool/sub_nodes_private

- job:
    name: 'tripleo-quickstart-deploy'
    defaults: global
    scm:
      - git:
          url: https://git.openstack.org/openstack/tripleo-common
      - git:
          url: https://git.openstack.org/openstack/tripleo-quickstart

    builders:
      - oooq_dlrn_build_packages
      - setup_multinode
      - create_multinode_inventory
      - shell: |
          # Temporary while we don't have a quickstart project in review.rdoproject.org
          # Remove when we do.
          cd ${WORKSPACE}
          git clone https://git.openstack.org/openstack/tripleo-quickstart

          mkdir -p ${WORKSPACE}/workdir
          cd ${WORKSPACE}/tripleo-quickstart
          sudo ./quickstart.sh --install-deps

          # FIXME: Some ansible resources don't respect the ssh config
          echo 'ssh_args="-F ${WORKSPACE}/workdir/ssh.config.local.ansible"' \
              >> ansible.cfg

          QUICKSTART_ARGS="--no-clone \
                           --retain-inventory \
                           --working-dir ${WORKSPACE}/workdir/ \
                           -t undercloud-scripts,undercloud-install,overcloud-scripts \
                           -T none \
                           -v \
                           -e undercloud_local_interface=br-ex \
                           -e ssh_user=stack \
                           -e ansible_ssh_user=stack \
                           -p quickstart-extras.yml \
                           -r quickstart-extras-requirements.txt"

          # The Virthost argument uses 127.0.0.2 to run the playbook against
          # localhost, but avoid Ansible's 'local' connection type
          sudo ./quickstart.sh ${QUICKSTART_ARGS} 127.0.0.2

          # Finish the installation
          ssh -F ${WORKSPACE}/workdir/ssh.config.local.ansible undercloud ./undercloud-install.sh

          # TODO: Modify this to use the multinode heat templates in newton-forward
          ssh -F ${WORKSPACE}/workdir/ssh.config.local.ansible undercloud ./overcloud-deploy.sh

          ssh -F ${WORKSPACE}/workdir/ssh.config.local.ansible undercloud ./overcloud-deploy-post.sh
          ssh -F ${WORKSPACE}/workdir/ssh.config.local.ansible undercloud ./overcloud-validate.sh

    triggers:
      - zuul
    node: bare-centos-7-2-node
